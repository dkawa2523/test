以下では、**OES-CR（Optical Emission Spectroscopy – Collisional Radiative）順問題**（プラズマパラメータ → 発光スペクトル）を基盤にして、**時間変化する実測スペクトル** (y(\lambda,t)) から **各時刻の電子温度 (T_e(t))、電子密度 (n_e(t))**（＋必要ならガス温度、種密度、装置応答など）を **高速・高精度に逆推定**するための「解析手法」を、用途が被らないように**カテゴリー分け**し、**区分ごとにテーブル**で整理します。

---

## 背景

* OES は **波長軸 (\lambda)** だけでなく、パルス放電・変調・不安定性などにより **時間軸 (t)** に沿ってスペクトルが変化する。
* CR モデル（あるいは PEC/放射係数テーブル）は、与えた (T_e, n_e,\dots) から **線強度・連続光・線形状**（＋自己吸収や視線積分など）を計算できるため、順問題は定義できる。
* 逆問題（スペクトル→(T_e,n_e)）は **非線形・多峰性・縮退**（似たスペクトルを別パラメータが生成）になりやすく、単純な最小二乗だけだと不安定になりがち。
* 実運用では、**(1) 順計算が重い**、**(2) 実測には装置応答/背景/波長ズレ/分解能/ノイズ**が混ざる、**(3) 時系列として整合した推定**が欲しい、という要求が重なる。

---

## 課題

* **時間方向の整合性**：時刻ごとに独立推定するとノイズに引きずられ、物理的に不連続な (T_e(t),n_e(t)) が出やすい
* **シミュレーション→実測（sim-to-real）ギャップ**：装置関数・背景光・自己吸収・未モデリング線などで系統誤差が出る
* **逆問題の不適切性（ill-posed）**：線選択・線重なり・温度/密度の感度領域で推定が壊れる
* **高速性**：全時刻で MCMC/NS を回すと現実的でない（特に長時間波形）

---

## 目的

* **OES-CR で生成した疑似データ（ノイズ付与、装置応答乱数化など）**でサロゲートを学習し、
* 推論時は **実測の時間変化 (y(\lambda,t))** を取り込みながら、
* **高速（オンライン/準オンライン）**かつ**精度良く** (T_e(t),n_e(t)) を推定し、
* 可能なら **不確かさ（誤差棒）**も出して、論文化可能な新規性（時系列・校正・不確かさ・能動学習など）を含める。

---

# カテゴリーA：順モデル（サロゲート）＋時系列推定（データ同化・最適化）

> 「**物理で定義された観測モデル**」を中心に、時間方向の滑らかさやダイナミクスを入れて推定する枠組み。
> **“波長×時間の高次元観測” を時系列推定へ落とし込む**のに強いです。

| 手法                                              | 概要                                                                                                                                   | メリット                                                                                  | デメリット                                                                      | ライブラリー                                            | 実装コスト |                                  必要データ数（合成） | 本問題での有用性 / 区分内順位         | 新規性・論文可能性                                                                                                             | 参考文献（年月日）                                                                                                               |
| ----------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- | ------------------------------------------------- | ----- | ------------------------------------------: | ------------------------ | --------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| **A1. PEC物理因子分解サロゲート + EnKF/UKF + スムーザ（固定ラグ等）** | 状態空間モデル：(\theta_t=[T_e(t),n_e(t),…]) を「ゆっくり変化（例：ランダムウォーク or 低次動力学）」とし、観測 (y_t) は **PEC-MLP等の順サロゲート**で予測。EnKF/UKF で逐次推定し、平滑化で時間整合を取る。 | **時系列の整合性が強い**（ノイズに頑健）／逐次処理で高速／不確かさ（共分散）が自然に出る／**装置パラメータ（感度関数、波長ズレ）も拡張状態として同時推定**しやすい | 高次元スペクトルをそのまま扱うと重い→**圧縮/特徴量化**が必要／EnKFは近似ガウス前提で多峰性に弱い場合／Q,R（過程/観測ノイズ）設計が効く | filterpy, DAPPER, 自作EnKF/UKF, PyTorch/JAX（順サロゲート） | 中〜高   | **順サロゲート学習**：(10^4\sim10^6)（パラメータ次元と精度要求次第） | **非常に高い / 1位**           | **高**：OES-CR＋KFは存在するが、(i) 物理因子分解PEC-MLP、(ii) 波長×時間の扱い（圧縮＋同化）、(iii) 装置校正を拡張状態で同時推定、(iv) 実測適応（sim-to-real）まで一体化で論文化しやすい | EnKF+CRM+OESで電子ダイナミクス推定の例（IEPC 2025-09-14開始） ([Janus Electric Propulsion][1])／UKF基礎（2004-11-08） ([Semantic Scholar][2]) |
| **A2. バッチMAP（正則化付き最小化）+ 自動微分（時間方向スムーズ項）**       | 目的関数 (\sum_t|y_t-h(\theta_t)|^2 + \sum_t|\theta_t-\theta_{t-1}|^2) を最適化（LBFGS/Adam等）。滑らかさは事前分布（ガウス）と等価。                              | 実装が比較的素直／制約（非負、単調等）を入れやすい／スムーズ項で時系列整合／EnKFより**非線形に強い**ことも                             | 長い時系列だと最適化が重い／初期値依存・局所解／誤差棒は近似（ヘッセ等）                                       | PyTorch/JAX（autodiff）, SciPy optimize             | 中     |                    (10^4\sim10^6)（順サロゲート学習） | **高い / 2位**              | **中〜高**：露光時間による時間平均（積分）を観測モデルに入れたMAP、装置応答も同時推定、などで論文化余地                                                               | OESのベイズ推定（時間平均スペクトル）例：2025-02-14 ([ResearchGate][3])                                                                    |
| **A3. 線比・線幅など特徴量化 → 低次元逆推定 + 時系列平滑化**           | スペクトルからピーク面積/比/半値幅などの特徴を抽出し、低次元の順サロゲートで逆推定→最後に平滑化（移動平均、スプライン、KF等）。                                                                   | 立ち上げが速い／sim-to-realギャップが小さくなりやすい（装置の癖が“特徴抽出”で相殺される場合）／計算が非常に軽い                        | 情報落ち（線重なり・自己吸収・背景）で破綻しやすい／特徴抽出自体がノイズに弱い                                    | lmfit/SciPy + filterpy                            | 低〜中   |                              (10^3\sim10^5) | **中 / 3位（ただし初期PoCには有用）** | **低〜中**：新規性は出しにくいが、A1/A2の比較ベースラインとして重要                                                                                | （時間平均OESのベイズ推定で線形状を扱う例）2025-02-14 ([ResearchGate][3])                                                                   |

---

# カテゴリーB：SBI（Simulation-Based Inference：確率的逆推定の“学習済み推論器”）

> **疑似データ（CRで生成）→推論器を学習**し、実測では**1回のNN推論で posterior** を出す路線。
> “高速” と “不確かさ” を両立しやすい一方、**sim-to-real対策が鍵**。

| 手法                                                                | 概要                                                                                                                                        | メリット                                                                     | デメリット                                                           | ライブラリー                                      | 実装コスト |                              必要データ数（合成） | 本問題での有用性 / 区分内順位 | 新規性・論文可能性                                                      | 参考文献（年月日）                                                                                                                          |
| ----------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ | --------------------------------------------------------------- | ------------------------------------------- | ----- | --------------------------------------: | ---------------- | -------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| **B1. NPE（Neural Posterior Estimation）+ 正規化フロー + スペクトル/時系列エンコーダ** | ((\theta, y)) を大量生成し、(q_\phi(\theta\mid y)) を学習。出力は点推定でなく**事後分布**。時系列は (i) 窓 (y_{t-k:t+k}) を条件にする、(ii) (\theta_t) の時間事前を別途入れてスムージングする、など。 | 推論が極めて高速（時刻ごとにNN1回）／**多峰性・相関**も表現可能／不確かさ込みで出せる／大量データの学習が可能（疑似データ生成と相性良い） | 学習が重い／sim-to-realで posterior が系統的にズレる恐れ→ドメイン適応・校正が必須／エンコーダ設計が効く | **sbi**（PyTorch）, nflows, PyTorch Lightning | 高     | (10^5\sim10^7)（ただしmulti-roundや能動学習で削減可） | **非常に高い / 1位**   | **高**：OES-CR × SBI × 時系列（窓条件/遷移事前/露光積分）× sim-to-real補正は論文化しやすい | sbiツールキット（公開：2020-08-21） ([JOSS][4])／正規化フロー総説（公開：2021-01-01） ([ACM Digital Library][5])／NPEでスペクトルフィットの実証例（2024-01-11） ([arXiv][6]) |
| **B2. 時系列SBI（Markov因子分解・Compositional SBI 等）**                    | 長い時系列をそのまま条件付けせず、**マルコフ構造**で分割して推定をスケールさせる（例：遷移×観測の因子分解）。                                                                                 | 長系列に強い／時間構造を明示でき、物理的事前（滑らかさ等）を入れやすい                                      | 実装が難しい／モデル化（遷移の仮定）が外れると劣化                                       | sbi + 自作、Pyro/NumPyro                       | 高     |                          (10^5\sim10^7) | **高 / 2位**       | **高**：OESの時間分解推定に本質的に刺さる。時間SBIの応用例として論文化しやすい                   | 時系列SBI（公開：2025-01-22） ([OpenReview][7])                                                                                            |
| **B3. “SBIで高速事後” + “局所ベイズ補正（IS/MCMC/NS）”**                        | まずNPEで近似事後を出し、**尤度が書ける**（例：ガウス/ポアソン雑音、装置応答込み）なら、重要度サンプリングや短いMCMC/NSで補正。                                                                   | sim-to-realや近似誤差を補正しやすい／“近似→厳密”の道筋を作れる（信頼性が上がる）                          | 補正分だけ推論コスト増（ただしフルMCMCよりは軽い）／尤度モデルが必要                            | dynesty/emcee/NumPyro + sbi                 | 中〜高   |               SBI学習 (10^5) 程度 + 補正は観測ごと | **中〜高 / 3位**     | **中〜高**：OESでは露光積分・背景・分解能の尤度モデル化が新規性になりやすい                      | NPE＋（提案分布の絞り込み等）でのスペクトル推定例（2024-01-11） ([arXiv][6])／時間平均OESのベイズ推定（2025-02-14） ([ResearchGate][3])                                  |

---

# カテゴリーC：直接逆写像（回帰）としての時系列モデル

> 「逆問題を**回帰**として一気に解く」路線。
> **推論は最速**になりやすいが、**不確かさ・頑健性**は工夫が必要（ただし疑似データ大量生成と相性は良い）。

| 手法                                                       | 概要                                                     | メリット                               | デメリット                                          | ライブラリー                                     | 実装コスト |     必要データ数（合成） | 本問題での有用性 / 区分内順位     | 新規性・論文可能性                                                   | 参考文献（年月日）                                                |
| -------------------------------------------------------- | ------------------------------------------------------ | ---------------------------------- | ---------------------------------------------- | ------------------------------------------ | ----- | -------------: | -------------------- | ----------------------------------------------------------- | -------------------------------------------------------- |
| **C1. スペクトルエンコーダ（1D-CNN等）+ TCNで (\theta(t)) をseq2seq回帰** | 波長方向をCNNで特徴抽出し、時間方向はTCN（拡張畳み込み）で系列回帰。窓入力で因果/非因果どちらも可能。 | 推論が非常に高速／長系列でも安定しやすい（RNNより）／実装しやすい | 不確かさが出にくい（工夫必要：分位点回帰・アンサンブル等）／sim-to-realに弱い場合 | PyTorch, Lightning                         | 中     | (10^4\sim10^6) | **高 / 1位（回帰カテゴリ内）**  | **中**：物理因子分解特徴＋TCN、自己教師あり事前学習＋微調整などで論文化余地                   | TCN基礎（2018-03-04） ([arXiv][8])                           |
| **C2. Transformer系（時間×波長の2次元をトークン化、または時系列Attention）**    | 波長ビンやスペクトル潜在をトークン化し、Attentionで時間相関を学習。                 | 大規模データで強い／長距離依存を捉えやすい              | 学習コスト高／データ少ないと不安定                              | PyTorch, xformers, JAX/Flax                | 高     | (10^5\sim10^7) | **中〜高 / 2位**         | **中〜高**：OESの“波長×時間”をTransformerで扱うのは見栄えが良く、工夫（物理制約・校正）で論文化可 | Transformer基礎（2017-06-12） ([arXiv][9])                   |
| **C3. 軽量ML（AutoGluon/XGBoost/RF）+ 時系列平滑化**               | スペクトルをPCA/AE/手特徴で圧縮→回帰（GBDT等）→平滑化。                     | 立ち上げが速い／少データでもそこそこ動く／推論が非常に軽い      | 高度な非線形や多峰性に弱い／不確かさは工夫が必要                       | AutoGluon, XGBoost, LightGBM, scikit-learn | 低〜中   | (10^3\sim10^5) | **中 / 3位（ただしPoC最強）** | **低〜中**：単体新規性は弱いが、OES向け特徴設計（PEC因子分解）と組み合わせると価値が出る           | PrismSPECT合成スペクトルを用いた密度・温度回帰の例（2023-08-31） ([arXiv][10]) |

---

# カテゴリーD：sim-to-real（実測適用）を成立させる頑健化・校正

> ここは「どの推定法でも必要」になりやすい“土台”です。
> 疑似データ学習→実測推論の前提だと、**ここを入れるかどうかで成功確率が大きく変わる**ことが多いです。

| 手法                                                     | 概要                                                                                                          | メリット                               | デメリット                             | ライブラリー                              | 実装コスト |               必要データ数（合成/実測） | 本問題での有用性 / 区分内順位 | 新規性・論文可能性                                  | 参考文献（年月日）                                      |
| ------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------- | ---------------------------------- | --------------------------------- | ----------------------------------- | ----- | --------------------------: | ---------------- | ------------------------------------------ | ---------------------------------------------- |
| **D1. ドメインランダム化（疑似データ生成時に装置差・背景・分解能・波長ズレを乱数化）**        | 合成データ側で、(a) 感度関数 (S(\lambda))、(b) 迷光/背景、(c) 分解能（PSF）、(d) 波長オフセット、(e) ノイズ統計などを幅広く乱数化。                        | 実装が比較的簡単／実測への頑健性が上がりやすい／追加の実測ラベル不要 | 乱数化範囲が広すぎると学習が難しくなる／物理的でない乱数化は逆効果 | NumPy/PyTorch前処理                    | 低〜中   |         合成は増える（×数倍）／実測ラベル不要 | **非常に高い / 1位**   | **中**：OES固有の乱数化（線広がり、自己吸収、視線積分）設計が新規性になり得る | Domain Randomization（2017-03-20） ([arXiv][11]) |
| **D2. ドメイン適応（DANN等：実測“ラベルなし”スペクトルで特徴分布を整合）**           | シミュレーション（ラベルあり）と実測（ラベルなし）を同時に入れ、**ドメイン判別器に勝つ特徴**を学習してギャップを縮める。                                              | 実測のラベルが要らない／SBIや回帰の前段エンコーダに効く      | 学習が不安定な場合／ドメインが違いすぎると破綻           | PyTorch（GRL実装）, domain-adaptation実装 | 中     |           実測はラベルなしで良い（大量推奨） | **高い / 2位**      | **中〜高**：OESで“ラベルなし適応”は価値が高く、論文化しやすい        | DANN（2015-05-28） ([arXiv][12])                 |
| **D3. 残差校正ネット（y_sim→y_realの差分を学習、または装置モデルを拡張状態で同時推定）** | 例：(y_{\text{real}}(\lambda,t)=a(\lambda)y_{\text{sim}}+b(\lambda)+r_\psi(\lambda,t))。残差を小さく学習する（ResNet的発想）。 | 小量の実測ラベルでも効く／未モデリング線・背景に対処しやすい     | 校正が過学習すると物理推定が崩れる（識別性が重要）         | PyTorch                             | 中     | 実測ラベルが少数でも可（(10^1\sim10^3)） | **中〜高 / 3位**     | **高**：装置校正と物理推定の“同時推定”設計は論文化ポイントになりやすい     | Residual learning（2015-12-10） ([arXiv][13])    |

---

# カテゴリーE：順問題（OES-CR/PEC）の高速化サロゲート設計

> 逆問題の性能は、**順モデルサロゲートの設計**で大きく変わります。
> 特にあなたが重視している **「物理因子分解MLP（PEC予測＋既知スケーリング）」**は、sim-to-realにも効きやすい有力候補です。

| 手法                                                 | 概要                                                                                                                                           | メリット                                                       | デメリット                              | ライブラリー                    | 実装コスト |            必要データ数（合成） | 本問題での有用性 / 区分内順位            | 新規性・論文可能性                                           | 参考文献（年月日）                                                     |
| -------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- | ---------------------------------- | ------------------------- | ----- | --------------------: | --------------------------- | --------------------------------------------------- | ------------------------------------------------------------- |
| **E1. 物理因子分解PEC-MLP（PEC予測＋既知スケーリング）**              | MLPは「線ごとのPEC/放射係数」など**中間物理量**を予測し、最終スペクトルは (I_{ul}\propto n_e n_{\text{species}} \text{PEC}_{ul}(T_e,n_e,...) ) 等の**既知スケーリング**で組み立てる（＋装置応答）。 | **外挿に強くなりやすい**／物理整合が取りやすい／線ごとの寄与が見えてデバッグ容易／逆問題での識別性が上がりやすい | 設計（どの中間量を学習するか）が肝／自己吸収や視線積分を入れると複雑 | PyTorch/JAX               | 中     |        (10^4\sim10^6) | **非常に高い / 1位**              | **高**：PEC-MLP＋時系列推定（A1/B1）＋装置同時推定（D3）まで統合すると論文化しやすい | CRサロゲート（ANN）自体の例（2021-12-10） ([arXiv][14])                    |
| **E2. 能動学習（Adaptive sampling）でCR計算点を削減して学習効率化**    | 誤差が大きい領域を見つけて追加計算することで、合成データ生成コストを削減。                                                                                                        | **CR計算コストを1桁削減**などが狙える／高次元でも効きやすい                          | ループ設計が必要／実装がやや重い                   | BoTorch, Optuna, 自作AL     | 中〜高   | “必要なところだけ”追加（全体を減らせる） | **高い / 2位**                 | **高**：OES-CRのデータ生成を“推定精度最大化”で最適化するのは論文化に向く          | CRサロゲートの適応サンプリング（v1: 2021-12-10、改訂: 2022-09-26） ([arXiv][14]) |
| **E3. 非定常CR（時間依存ODE）を潜在空間＋Flow-mapで学習（パルス/過渡に対応）** | 物理補助AEで低次元潜在を作り、Flow-map NNで剛性の強いCRダイナミクスを近似。                                                                                                | パルス放電など「準定常が破れる」場合に効く／順問題が劇的に軽くなる可能性                       | 学習が難しい／データが巨大化しやすい／逆問題はさらに設計が必要    | PyTorch/JAX, torchdiffeq等 | 高     | (10^6\sim10^8)（ケース次第） | **中〜高 / 3位（必要条件が合えば一気に重要）** | **高**：OESの時間分解推定で“非定常CRを含む”は強い論文化テーマ                | 非定常CRの潜在ダイナミクス学習（v1: 2024-09-01） ([arXiv][15])                |

---

# 本問題（時間変化OES → (T_e(t), n_e(t))）での総合優先度（おすすめ順）

「**疑似データ学習＋実測時系列推論**」という前提を最大限に活かしつつ、失敗しにくい順に並べます。

1. **A1（PEC因子分解サロゲート + EnKF/UKF + スムーザ） + D1（ドメインランダム化）**

   * 時系列整合・不確かさ・高速性のバランスが良い。
   * さらに拡張状態で装置パラメータも推定しやすく、実測適用が現実的。
   * EnKF+CRM+OESの先行例もあり、研究の筋が通る。 ([Janus Electric Propulsion][1])

2. **B1（SBI: NPE+Flow） + D1/D2（sim-to-real対策）**

   * 推論が最速クラスで、事後分布が出せる。
   * ただし sim-to-real を放置すると破綻しやすいので、Dカテゴリとセット運用が前提。 ([JOSS][4])

3. **A2（バッチMAP）**

   * A1が難しい場合の堅実ルート。実装しやすく、露光積分なども入れやすい。
   * まずこれで “物理モデル＋時系列正則化” の土台を固めるのは強い。

4. **C1（CNN+TCN） / C2（Transformer）**

   * 工学的には最速にできるが、**信頼性（不確かさ・外れ値）**を別途設計しないと運用が怖い。
   * ただし疑似データ大量生成ができる環境なら、十分実用候補。

5. **E3（非定常CRダイナミクスの学習）**

   * **準定常仮定が破れている**（パルス立上りなど）なら急に重要度が上がる。
   * 逆に準定常で足りるなら後回しで良い。

---

# 論文化を狙いやすい「新規性の出しどころ」案（手法横断）

各カテゴリの良いところを組み合わせると、第三者に刺さる “新規性” が作れます。

* **（新規性A）拡張状態推定：プラズマパラメータ＋装置校正を同時推定**

  * 例：(\theta_t=[T_e,n_e]) に加え、(S(\lambda))（感度関数の低次元表現）、波長シフト、分解能などを同時推定（A1/A2/D3統合）。
* **（新規性B）露光時間・ゲート幅を含む観測モデル**

  * 実測 (y_t) が厳密には「区間平均」なら、(y_t=\int_{t-\Delta/2}^{t+\Delta/2} h(\theta(\tau))d\tau) を観測方程式として入れる（A2やB3が得意）。
* **（新規性C）能動学習でCR計算点を最適化**

  * “推定誤差が大きい領域” を狙って合成データを追加生成（E2）。OESの感度領域（線比が効く領域）と結びつけると説得力が強い。 ([arXiv][14])
* **（新規性D）SBIの事後を、少計算の補正で“校正済み”にする**

  * NPEで出した事後を、尤度が書ける範囲でIS/MCMCで補正（B3）。スペクトル推定での先行があるので筋が良い。 ([arXiv][6])

---

必要なら次に、あなたの前提（測定：どの波長域・分解能・ゲート幅・線種、推定したいパラメータの次元、準定常仮定の妥当性）を“仮置き”したうえで、

* **A1（EnKF/UKF）を成立させるための具体設計**（観測圧縮、状態遷移、Q/R設計、拡張状態の持ち方、計算量見積もり）
* **B1（SBI）でのネットワーク構成**（スペクトルエンコーダ、時系列コンテキスト、multi-round戦略、SBC/診断）
* **E1（PEC因子分解MLP）を時間推定へ接続する実装案**（線ごとのloss、物理制約、自己吸収/装置応答の入れ方）

まで落として、研究計画として一枚に整理することもできます。

[1]: https://januselectricpropulsion.com/sites/default/files/2025-11/IEPC_2025-674_DataAssimilation.pdf "https://januselectricpropulsion.com/sites/default/files/2025-11/IEPC_2025-674_DataAssimilation.pdf"
[2]: https://www.semanticscholar.org/paper/Unscented-filtering-and-nonlinear-estimation-Julier-Uhlmann/3e7466d3583cbe567a6da3f98119678d693628d2 "https://www.semanticscholar.org/paper/Unscented-filtering-and-nonlinear-estimation-Julier-Uhlmann/3e7466d3583cbe567a6da3f98119678d693628d2"
[3]: https://www.researchgate.net/publication/387929131_Bayesian_method_in_optical_emission_spectroscopy_temporal_evolution_of_electron_density_from_time-integrated_Ha_emission_and_validation_with_time-resolved_measurements_for_pulsed_nanosecond_discharges "https://www.researchgate.net/publication/387929131_Bayesian_method_in_optical_emission_spectroscopy_temporal_evolution_of_electron_density_from_time-integrated_Ha_emission_and_validation_with_time-resolved_measurements_for_pulsed_nanosecond_discharges"
[4]: https://joss.theoj.org/papers/10.21105/joss.02505 "https://joss.theoj.org/papers/10.21105/joss.02505"
[5]: https://dl.acm.org/doi/abs/10.5555/3546258.3546315 "https://dl.acm.org/doi/abs/10.5555/3546258.3546315"
[6]: https://arxiv.org/abs/2401.06061 "https://arxiv.org/abs/2401.06061"
[7]: https://openreview.net/forum?id=uClUUJk05H "https://openreview.net/forum?id=uClUUJk05H"
[8]: https://arxiv.org/abs/1803.01271?utm_source=chatgpt.com "An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling"
[9]: https://arxiv.org/abs/1706.03762 "https://arxiv.org/abs/1706.03762"
[10]: https://arxiv.org/abs/2308.16828 "https://arxiv.org/abs/2308.16828"
[11]: https://arxiv.org/abs/1703.06907?utm_source=chatgpt.com "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World"
[12]: https://arxiv.org/abs/1505.07818 "https://arxiv.org/abs/1505.07818"
[13]: https://arxiv.org/abs/1512.03385 "https://arxiv.org/abs/1512.03385"
[14]: https://arxiv.org/abs/2112.05325 "https://arxiv.org/abs/2112.05325"
[15]: https://arxiv.org/abs/2409.05893 "https://arxiv.org/abs/2409.05893"
